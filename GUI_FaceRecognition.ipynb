{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/rcmalli/keras-vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20dcd7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in c:\\users\\cz3\\anaconda3\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\cz3\\anaconda3\\lib\\site-packages (from keras_applications) (1.21.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\cz3\\anaconda3\\lib\\site-packages (from keras_applications) (3.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4ff220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn\n",
      "  Using cached mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\cz3\\anaconda3\\lib\\site-packages (from mtcnn) (2.11.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\cz3\\anaconda3\\lib\\site-packages (from mtcnn) (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\cz3\\anaconda3\\lib\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.21.5)\n",
      "Installing collected packages: mtcnn\n",
      "Successfully installed mtcnn-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4f36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "7/7 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 643ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "7/7 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 608ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 747ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 658ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "An error occurred: list index out of range\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 623ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\CZ3\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\CZ3\\AppData\\Local\\Temp\\ipykernel_7816\\2124758866.py\", line 94, in process_images\n",
      "    vggface_resnet = VGGFace(model='resnet50')\n",
      "NameError: name 'VGGFace' is not defined\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "import time\n",
    "# for loading/processing the images\n",
    "# from tensorflow.keras.utils import load_img\n",
    "# from tensorflow.keras.utils import img_to_array\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# models\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.models import Model\n",
    "# import keras\n",
    "# # import keras_vggface\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import mtcnn\n",
    "# from keras.utils.data_utils import get_file\n",
    "# import keras_vggface.utils\n",
    "# import tensorflow as tf\n",
    "# import PIL\n",
    "\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "# To access Google Drive:\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/gdrive\")\n",
    "\n",
    "def convert_arw_to_jpg(path):\n",
    "    os.chdir(path)\n",
    "    face_img = []\n",
    "\n",
    "    [file for file in os.listdir(path) if file.lower().endswith('.arw')]\n",
    "\n",
    "    # creates a ScandirIterator aliased as files\n",
    "    with os.scandir(path) as files:\n",
    "        # loops through each file in the directory\n",
    "        for file in files:\n",
    "            if file.name.lower().endswith('.jpg'):\n",
    "                face_img.append(file.name)\n",
    "    return face_img\n",
    "\n",
    "def get_videos(path):\n",
    "    os.chdir(path)\n",
    "    face_vid = []\n",
    "    with os.scandir(path) as files:\n",
    "        for file in files:\n",
    "            if file.name.lower().endswith('.mp4'):\n",
    "                face_vid.append(file.name)\n",
    "    return face_vid\n",
    "    \n",
    "def get_mtcnn(img):\n",
    "  photo = plt.imread(img)\n",
    "  face_detector = mtcnn.MTCNN()\n",
    "  face_roi = face_detector.detect_faces(photo)\n",
    "  x1, y1, width, height = face_roi[0]['box']\n",
    "  # width, height = width+100 , height+150\n",
    "  x2, y2 = x1 + width, y1+height\n",
    "  face = photo[y1:y2, x1:x2]\n",
    "  # print(face)\n",
    "  return face\n",
    "\n",
    "def extract_features(img, model):\n",
    "  # print(img.shape)\n",
    "  img = Image.fromarray(img)\n",
    "  img = img.resize((224,224),Image.ANTIALIAS)\n",
    "  resized_image_array = np.array(img)\n",
    "  # print(\"resized image: \",resized_image_array.shape)\n",
    "  reshaped_img = resized_image_array.reshape(1,224, 224,3)\n",
    "  # print(\"model reshape image : \", reshaped_img.shape)\n",
    "  imgx = preprocess_input(reshaped_img)\n",
    "  # print(imgx.shape)\n",
    "  features = model.predict(imgx, use_multiprocessing=True)\n",
    "  # print(\"features: \",features)\n",
    "\n",
    "  return features\n",
    "\n",
    "def get_top_frames_faces(video):\n",
    "  cap = cv2.VideoCapture(path+'/'+video)\n",
    "\n",
    "  if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "  frames = []\n",
    "  frames_with_faces = []\n",
    "  frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "  elapsed_time = 0\n",
    "  faces_confidence = []\n",
    "  face_detector = mtcnn.MTCNN()\n",
    "\n",
    "  while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    elapsed_time += 1\n",
    "\n",
    "    if elapsed_time >= frame_rate:\n",
    "      face_roi = face_detector.detect_faces(frame);\n",
    "\n",
    "      if face_roi!=[]:\n",
    "        print(frame.shape)\n",
    "        x1, y1, width, height = face_roi[0]['box']\n",
    "        x2, y2 = x1 + width, y1+height\n",
    "        face = frame[y1:y2, x1:x2]\n",
    "        print(face.shape)\n",
    "        frames_with_faces.append(face)\n",
    "        frames.append(frame)\n",
    "        faces_confidence.append(face_roi[0]['confidence'])\n",
    "        elapsed_time = 0\n",
    "      print(len(frames))\n",
    "\n",
    "    # frames.append(frame)\n",
    "    if len(frames_with_faces) ==2:\n",
    "      break\n",
    "  cap.release()\n",
    "  # top_ids = np.argsort(faces_confidence)[::-1][:2]\n",
    "  # top_frames = [frames[i] for i in top_ids]\n",
    "  # top_faces = [frames_with_faces[i] for i in top_ids]\n",
    "  top_face_id = np.argmax(faces_confidence)\n",
    "  print(top_face_id)\n",
    "  top_frame = frames[top_face_id]\n",
    "  top_face = frames_with_faces[top_face_id]\n",
    "  return top_frame, top_face\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to handle image processing (simulated with a sleep)\n",
    "def process_images():\n",
    "    image_path = entry_image_path.get()\n",
    "    num_people = entry_num_people.get()\n",
    "    final_path = entry_final_path.get()\n",
    "\n",
    "    if not final_path:\n",
    "        messagebox.showerror(\"Error\", \"Please Select the destination folder\")\n",
    "        return\n",
    "\n",
    "    if not image_path:\n",
    "        messagebox.showerror(\"Error\", \"Please Select the Image folder\")\n",
    "        return\n",
    "\n",
    "    if not num_people:\n",
    "        messagebox.showerror(\"Error\", \"Please enter the Total Number of People.\")\n",
    "        return\n",
    "    progress_var.set(1)\n",
    "    progress_label.config(text=f\"Loading Data from the path: 1%\")\n",
    "    face_img = convert_arw_to_jpg(image_path)\n",
    "    \n",
    "    data = {}\n",
    "    progress_var.set(5)\n",
    "    progress_label.config(text=f\"Detecting Faces: 5%\")\n",
    "    aa = 45/len(data.keys)\n",
    "    lp = 0\n",
    "    for face in face_img:\n",
    "        # print(face)\n",
    "        try:\n",
    "            lp=lp+aa\n",
    "            lp = round(lp, 2)\n",
    "            progress_var.set(lp)\n",
    "            progress_label.config(text=f\"Detecting Face:{face} {lp}%\")\n",
    "            feat = get_mtcnn(face)\n",
    "            data[face] = feat\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "    progress_var.set(50)\n",
    "    progress_label.config(text=f\"Loading Feature Extraction Models: 50%\")\n",
    "    filenames = np.array(list(data.keys()))\n",
    "    vggface_resnet = VGGFace(model='resnet50')\n",
    "    vggface_resnet = Model(inputs=vggface_resnet.inputs, outputs=vggface_resnet.layers[-2].output)\n",
    "    \n",
    "    progress_var.set(55)\n",
    "    progress_label.config(text=f\"Extracting Features from faces: 55%\")\n",
    "    resnet_feat_data = {}\n",
    "    # loop through each image in the dataset\n",
    "    aa = 15/len(data.keys)\n",
    "    lp = 55\n",
    "    for face in data:\n",
    "        try:\n",
    "            lp=lp+aa\n",
    "            lp = round(lp, 2)\n",
    "            progress_var.set(lp)\n",
    "            progress_label.config(text=f\"Extracting Features from face:{face} {lp}%\")\n",
    "            feat = extract_features(data[face],vggface_resnet)\n",
    "            resnet_feat_data[face] = feat\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "    filenames = np.array(list(resnet_feat_data.keys()))\n",
    "    \n",
    "    progress_var.set(70)\n",
    "    progress_label.config(text=f\"preparing features for clustering: 70%\")\n",
    "    feat = np.array(list(resnet_feat_data.values()))\n",
    "    feat = feat.reshape(-1,feat.shape[2])\n",
    "    progress_var.set(72)\n",
    "    progress_label.config(text=f\"clustering faces based on features: 72%\")\n",
    "    x = feat\n",
    "    kmeans = KMeans(n_clusters=num_people, random_state=22)\n",
    "    kmeans.fit(x)\n",
    "    progress_var.set(75)\n",
    "    progress_label.config(text=f\"clustering faces based on features: 75%\")\n",
    "    groups = {}\n",
    "    for file, cluster in zip(filenames,kmeans.labels_):\n",
    "        if cluster not in groups.keys():\n",
    "            groups[cluster] = []\n",
    "            groups[cluster].append(file)\n",
    "        else:\n",
    "            groups[cluster].append(file)\n",
    "    progress_var.set(80)\n",
    "    progress_label.config(text=f\"clustering faces based on features: 80%\")\n",
    "            \n",
    "    cluster_centroids = kmeans.cluster_centers_\n",
    "    distance_threshold = 80\n",
    "#     merged_clusters = []\n",
    "    test = []\n",
    "    remaining_clusters = list(range(len(cluster_centroids)))\n",
    "    \n",
    "    progress_var.set(85)\n",
    "    progress_label.config(text=f\"clustering faces based on features: 85%\")\n",
    "    while remaining_clusters:\n",
    "        current_cluster = remaining_clusters[0]\n",
    "        clusters_to_merge = [current_cluster]\n",
    "        \n",
    "        for i in range(1, len(remaining_clusters)):\n",
    "            candidate_cluster = remaining_clusters[i]\n",
    "            \n",
    "            distance = euclidean(cluster_centroids[current_cluster], cluster_centroids[candidate_cluster])\n",
    "            \n",
    "            if distance < distance_threshold:\n",
    "                clusters_to_merge.append(candidate_cluster)\n",
    "        \n",
    "        if len(clusters_to_merge)>0:\n",
    "            merged_cluster = [k for c in clusters_to_merge for k in groups[c]]\n",
    "        else:\n",
    "            merged_cluster = groups[current_cluster]\n",
    "        \n",
    "        remaining_clusters = [c for c in remaining_clusters if c not in clusters_to_merge]\n",
    "        test.append(merged_cluster)\n",
    "        \n",
    "    progress_var.set(90)\n",
    "    progress_label.config(text=f\"Creating group folders: 90%\")\n",
    "    source_folder = image_path\n",
    "    output_path = final_path\n",
    "    dest_folders = [output_path+'/'+str(i) for i in range(0,len(test))]\n",
    "    for grp_folder in dest_folders:\n",
    "        if not os.path.exists(grp_folder):\n",
    "            os.makedirs(grp_folder)\n",
    "    progress_var.set(95)\n",
    "    progress_label.config(text=f\"Processing group folders: 95%\")\n",
    "    for i, grp_img in enumerate(test):\n",
    "        for img in grp_img:\n",
    "            source_path = os.path.join(source_folder, img)\n",
    "            destination_path = os.path.join(dest_folders[i], img)\n",
    "            shutil.copy(source_path, destination_path)\n",
    "    progress_var.set(100)\n",
    "    progress_label.config(text=f\"Processing Completed: 100%\")\n",
    "\n",
    "#     for i in range(101):\n",
    "#         progress_var.set(i)\n",
    "#         progress_label.config(text=f\"Processing: {i}%\")\n",
    "#         root.update_idletasks()\n",
    "#         time.sleep(0.05)\n",
    "\n",
    "    messagebox.showinfo(\"Image Processing\", f\"Processing images in folder: {image_path} for {num_people} people completed\")\n",
    "    # Reset input fields\n",
    "    entry_image_path.delete(0, tk.END)\n",
    "    entry_num_people.delete(0, tk.END)\n",
    "    entry_final_path.delete(0,tk.END)\n",
    "    entry_video_path.delete(0,tk.END)\n",
    "\n",
    "    # Reset the progress bar\n",
    "    progress_var.set(0)\n",
    "    # Reset the progress label\n",
    "    progress_label.config(text=\"\")\n",
    "\n",
    "\n",
    "# Function to handle video processing (simulated with a sleep)\n",
    "def process_video():\n",
    "    video_path = entry_video_path.get()\n",
    "    num_people = entry_num_people.get()\n",
    "    final_path = entry_final_path.get()\n",
    "\n",
    "    if not final_path:\n",
    "        messagebox.showerror(\"Error\", \"Please Select the destination folder\")\n",
    "        return\n",
    "    if not video_path:\n",
    "        messagebox.showerror(\"Error\", \"Please Select the Video folder\")\n",
    "        return\n",
    "    if not num_people:\n",
    "        messagebox.showerror(\"Error\", \"Please enter the Total Number of People.\")\n",
    "        return\n",
    "    \n",
    "    progress_var.set(1)\n",
    "    progress_label.config(text=f\"Loading Data from the path: 1%\")\n",
    "    face_vid = get_videos(path)\n",
    "    \n",
    "    frame_data = {}\n",
    "    face_data = {}\n",
    "    progress_var.set(5)\n",
    "    progress_label.config(text=f\"Detecting Faces: 5%\")\n",
    "    aa = 45/len(data.keys)\n",
    "    lp = 0\n",
    "    for face in vid_10:\n",
    "        # print(face)\n",
    "        try:\n",
    "            lp=lp+aa\n",
    "            lp = round(lp, 2)\n",
    "            progress_var.set(lp)\n",
    "            progress_label.config(text=f\"Detecting Face:{face} {lp}%\")\n",
    "            frame, feat = get_top_frames_faces(face)\n",
    "            frame_data[face] = frame\n",
    "            face_data[face] = feat\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "    filenames = np.array(list(frame_data.keys()))\n",
    "    \n",
    "    progress_var.set(50)\n",
    "    progress_label.config(text=f\"Loading Feature Extraction Models: 50%\")\n",
    "    vggface_resnet = VGGFace(model='resnet50')\n",
    "    vggface_resnet = Model(inputs=vggface_resnet.inputs, outputs=vggface_resnet.layers[-2].output)\n",
    "    \n",
    "    progress_var.set(55)\n",
    "    progress_label.config(text=f\"Extracting Features from faces: 55%\")\n",
    "    resnet_feat_data = {}\n",
    "    # loop through each image in the dataset\n",
    "    aa = 15/len(data.keys)\n",
    "    lp = 55\n",
    "    for face in face_data:\n",
    "        try:\n",
    "            lp=lp+aa\n",
    "            lp = round(lp, 2)\n",
    "            progress_var.set(lp)\n",
    "            progress_label.config(text=f\"Extracting Features from face:{face} {lp}%\")\n",
    "            feat = extract_features(face_data[face],vggface_resnet)\n",
    "            resnet_feat_data[face] = feat\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "    filenames = np.array(list(resnet_feat_data.keys()))\n",
    "    \n",
    "    progress_var.set(70)\n",
    "    progress_label.config(text=f\"preparing features for clustering: 70%\")\n",
    "    feat = np.array(list(resnet_feat_data.values()))\n",
    "    feat = feat.reshape(-1,feat.shape[2])\n",
    "    progress_var.set(72)\n",
    "    progress_label.config(text=f\"clustering faces based on features: 72%\")\n",
    "    x = feat\n",
    "    kmeans = KMeans(n_clusters=num_people, random_state=22)\n",
    "    kmeans.fit(x)\n",
    "    progress_var.set(75)\n",
    "    progress_label.config(text=f\"clustering faces based on features: 75%\")\n",
    "    groups = {}\n",
    "    for file, cluster in zip(filenames,kmeans.labels_):\n",
    "        if cluster not in groups.keys():\n",
    "            groups[cluster] = []\n",
    "            groups[cluster].append(file)\n",
    "        else:\n",
    "            groups[cluster].append(file)\n",
    "    progress_var.set(80)\n",
    "    progress_label.config(text=f\"clustering faces based on features: 80%\")\n",
    "            \n",
    "    cluster_centroids = kmeans.cluster_centers_\n",
    "    distance_threshold = 10\n",
    "#     merged_clusters = []\n",
    "    test = []\n",
    "    remaining_clusters = list(range(len(cluster_centroids)))\n",
    "    \n",
    "    progress_var.set(85)\n",
    "    progress_label.config(text=f\"clustering faces based on features: 85%\")\n",
    "    while remaining_clusters:\n",
    "        current_cluster = remaining_clusters[0]\n",
    "        clusters_to_merge = [current_cluster]\n",
    "        \n",
    "        for i in range(1, len(remaining_clusters)):\n",
    "            candidate_cluster = remaining_clusters[i]\n",
    "            \n",
    "            distance = euclidean(cluster_centroids[current_cluster], cluster_centroids[candidate_cluster])\n",
    "            \n",
    "            if distance < distance_threshold:\n",
    "                clusters_to_merge.append(candidate_cluster)\n",
    "        \n",
    "        if len(clusters_to_merge)>0:\n",
    "            merged_cluster = [k for c in clusters_to_merge for k in groups[c]]\n",
    "        else:\n",
    "            merged_cluster = groups[current_cluster]\n",
    "        \n",
    "        remaining_clusters = [c for c in remaining_clusters if c not in clusters_to_merge]\n",
    "        test.append(merged_cluster)\n",
    "        \n",
    "    progress_var.set(90)\n",
    "    progress_label.config(text=f\"Creating group folders: 90%\")\n",
    "    source_folder = image_path\n",
    "    output_path = final_path\n",
    "    dest_folders = [output_path+'/'+str(i) for i in range(0,len(test))]\n",
    "    for grp_folder in dest_folders:\n",
    "        if not os.path.exists(grp_folder):\n",
    "            os.makedirs(grp_folder)\n",
    "    progress_var.set(95)\n",
    "    progress_label.config(text=f\"Processing group folders: 95%\")\n",
    "    for i, grp_img in enumerate(test):\n",
    "        for img in grp_img:\n",
    "            source_path = os.path.join(source_folder, img)\n",
    "            destination_path = os.path.join(dest_folders[i], img)\n",
    "            shutil.copy(source_path, destination_path)\n",
    "    progress_var.set(100)\n",
    "    progress_label.config(text=f\"Processing Completed: 100%\")\n",
    "\n",
    "#     for i in range(101):\n",
    "#         progress_var.set(i)\n",
    "#         progress_label.config(text=f\"Processing: {i}%\")\n",
    "#         root.update_idletasks()\n",
    "#         time.sleep(0.05)\n",
    "\n",
    "    messagebox.showinfo(\"Video Processing\", f\"Processing videos in folder: {video_path} for {num_people} people completed\")\n",
    "    # Reset input fields\n",
    "    entry_image_path.delete(0, tk.END)\n",
    "    entry_num_people.delete(0, tk.END)\n",
    "    entry_final_path.delete(0, tk.END)\n",
    "    entry_video_path.delete(0, tk.END)\n",
    "\n",
    "    # Reset the progress bar\n",
    "    progress_var.set(0)\n",
    "    # Reset the progress label\n",
    "    progress_label.config(text=\"\")\n",
    "\n",
    "# Function to open a folder dialog and update the entry field\n",
    "def browse_for_folder(entry_field):\n",
    "    folder_path = filedialog.askdirectory()\n",
    "    entry_field.delete(0, tk.END)\n",
    "    entry_field.insert(0, folder_path)\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Face Recognition App\")\n",
    "\n",
    "window_width = 600\n",
    "window_height = 240\n",
    "root.geometry(f\"{window_width}x{window_height}\")\n",
    "root.resizable(False, False)\n",
    "\n",
    "\n",
    "# Define dark mode colors\n",
    "dark_color = \"#1E5128\"\n",
    "bg_input_color = \"#171C17\"\n",
    "dark_btn_color = \"#4E9F3D\"\n",
    "dark_background_color = \"#191A19\"\n",
    "dark_text_color = \"white\"\n",
    "\n",
    "# Set the background color for the dark mode theme\n",
    "root.configure(bg=dark_background_color)\n",
    "\n",
    "# Create labels, input fields, and buttons with dark mode theme\n",
    "label_image_path = tk.Label(root, text=\"Select Image Folder:\", bg=dark_background_color, fg=dark_text_color)\n",
    "entry_image_path = tk.Entry(root, width=40, bg=bg_input_color, fg=dark_text_color)\n",
    "button_browse_image = tk.Button(root, text=\"Browse\", command=lambda: browse_for_folder(entry_image_path) , bg=dark_color,fg=dark_text_color)\n",
    "button_image = tk.Button(root, text=\"Process Images\", command=process_images, bg=dark_btn_color,fg=dark_text_color)\n",
    "\n",
    "label_video_path = tk.Label(root, text=\"Select Video Folder:\", bg=dark_background_color, fg=dark_text_color)\n",
    "entry_video_path = tk.Entry(root, width=40, bg=bg_input_color,fg=dark_text_color)\n",
    "button_browse_video = tk.Button(root, text=\"Browse\", command=lambda: browse_for_folder(entry_video_path), bg=dark_color,fg=dark_text_color)\n",
    "button_video = tk.Button(root, text=\"Process Videos\", command=process_video, bg=dark_btn_color,fg=dark_text_color)\n",
    "\n",
    "label_num_people = tk.Label(root, text=\"Total Number of People:\", bg=dark_background_color, fg=dark_text_color)\n",
    "entry_num_people = tk.Entry(root, width=10, bg=bg_input_color,fg=dark_text_color)\n",
    "\n",
    "\n",
    "label_final_path = tk.Label(root, text=\"Select Output Folder:\", bg=dark_background_color, fg=dark_text_color)\n",
    "entry_final_path = tk.Entry(root, width=40, bg=bg_input_color, fg=dark_text_color)\n",
    "button_final_image = tk.Button(root, text=\"Browse\", command=lambda: browse_for_folder(entry_final_path) , bg=dark_color,fg=dark_text_color)\n",
    "\n",
    "\n",
    "# Create a custom style for the progress bar with a background color\n",
    "style = ttk.Style()\n",
    "style.configure(\"Custom.Horizontal.TProgressbar\", troughcolor=bg_input_color)\n",
    "\n",
    "# Create a progress bar with the custom style\n",
    "progress_var = tk.DoubleVar()\n",
    "progress = ttk.Progressbar(root, variable=progress_var, maximum=100, style=\"Custom.Horizontal.TProgressbar\")\n",
    "\n",
    "# Create a label to display progress text\n",
    "progress_label = tk.Label(root, text=\"\", bg=dark_background_color, fg=dark_text_color)\n",
    "\n",
    "\n",
    "# Arrange widgets using the grid layout manager\n",
    "label_image_path.grid(row=0, column=0, padx=10, pady=15, sticky=\"e\")\n",
    "entry_image_path.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_browse_image.grid(row=0, column=2, padx=10, pady=5)\n",
    "button_image.grid(row=0, column=3, padx=10, pady=5)\n",
    "\n",
    "label_video_path.grid(row=1, column=0, padx=10, pady=5, sticky=\"e\")\n",
    "entry_video_path.grid(row=1, column=1, padx=10, pady=5)\n",
    "button_browse_video.grid(row=1, column=2, padx=10, pady=5)\n",
    "button_video.grid(row=1, column=3, padx=10, pady=5)\n",
    "\n",
    "label_num_people.grid(row=2, column=0, padx=10, pady=5, sticky=\"e\")\n",
    "entry_num_people.grid(row=2, column=1, padx=10, pady=5)\n",
    "\n",
    "label_final_path.grid(row=3, column=0, padx=10, pady=15, sticky=\"e\")\n",
    "entry_final_path.grid(row=3, column=1, padx=10, pady=5)\n",
    "button_final_image.grid(row=3, column=2, padx=10, pady=5)\n",
    "\n",
    "progress.grid(row=5, column=0, columnspan=4, padx=10, pady=5, sticky=\"we\")\n",
    "progress_label.grid(row=4, column=0, columnspan=4, padx=10, pady=5, sticky=\"we\")\n",
    "\n",
    "# Start the main event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecdd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
